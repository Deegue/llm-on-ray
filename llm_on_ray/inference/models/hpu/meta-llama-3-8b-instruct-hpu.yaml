port: 8000
name: meta-llama-3-8b-instruct
route_prefix: /meta-llama-3-8b-instruct
num_replicas: 1
cpus_per_worker: 8
hpus_per_worker: 1
device: hpu
model_description:
  model_id_or_path: meta-llama/Meta-Llama-3-8b-Instruct
  tokenizer_name_or_path: meta-llama/Meta-Llama-3-8b-Instruct
  chat_template: "llm_on_ray/inference/models/templates/default_codellama.jinja"
  config:
    use_auth_token: ''
